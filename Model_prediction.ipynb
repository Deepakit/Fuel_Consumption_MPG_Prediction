{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Fuel Efficiency of Vehicles.\n",
    "\n",
    "   Selecting and training models\n",
    "   1. Select and train a few algorithms.\n",
    "   2. Evaluation using mean squared error.\n",
    "   3. Model Evaluation using Cross Validation.\n",
    "   4. Hyperparameter Tuning\n",
    "   5. Check Feature Importance \n",
    "   6. Evaluate final model\n",
    "   7. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA has been done on same data in different file. Please see the same for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the .data file using pandas\n",
    "\n",
    "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "auto_df=pd.read_csv(\"auto-mpg.data\",names=cols,na_values='?',comment='\\t',sep=\" \",skipinitialspace=True)\n",
    "data=auto_df.copy()\n",
    "\n",
    "split=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index,test_index in split.split(data,data['Cylinders']):\n",
    "    strat_train_set=data.loc[train_index]\n",
    "    strat_test_set=data.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregate independent and dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
       "145          4          83.0        61.0  2003.0          19.0          74   \n",
       "151          4          79.0        67.0  2000.0          16.0          74   \n",
       "388          4         156.0        92.0  2585.0          14.5          82   \n",
       "48           6         250.0        88.0  3139.0          14.5          71   \n",
       "114          4          98.0        90.0  2265.0          15.5          73   \n",
       "\n",
       "     Origin  \n",
       "145       3  \n",
       "151       2  \n",
       "388       1  \n",
       "48        1  \n",
       "114       2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=strat_train_set.drop('MPG',axis=1)\n",
    "data_label=strat_train_set[\"MPG\"].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the categorical \"Origin\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_origin_col(df):\n",
    "    df[\"Origin\"] = df[\"Origin\"].map({1: \"India\", 2: \"USA\", 3: \"Germany\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Custom Attribute Adder class\n",
    "Creating new features, information about same is present in EDA.ipynb, refer to same to understand it more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_acc,index_hp,index_cyl=4,2,0\n",
    "\n",
    "class FeatureAdder(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,acc_power=True):\n",
    "        self.acc_power=acc_power\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        acc_cylinder=X[:,index_acc]/X[:,index_cyl]\n",
    "        if self.acc_power:\n",
    "            acc_power=X[:,index_acc]/X[:,index_hp]\n",
    "            return np.c_[X,acc_power,acc_cylinder]\n",
    "        return np.c_[X,acc_cylinder]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function:\n",
    "    1) numeric_pipeline:Function to process numerical transformations\n",
    "                        Argument: data->original dataframe.\n",
    "                        Returns: num_attrs-> numerical dataframe\n",
    "                                 num_pipeline->numerical pipeline object\n",
    "                         \n",
    "    2) data_pipeline: Complete transformation pipeline for both numerical and categorical data.\n",
    "                      Argument: data-> original dataframe \n",
    "                      Returns: prepared_data-> transformed data, ready to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_pipeline(data):\n",
    "    numerics = ['float64', 'int64']\n",
    "    num_attrs = data.select_dtypes(include=numerics)\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attrs_adder', FeatureAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "    return num_attrs, num_pipeline\n",
    "\n",
    "\n",
    "def data_pipeline(data):\n",
    "    cat_attrs = [\"Origin\"]\n",
    "    num_attrs, num_pipeline = numeric_pipeline(data) #Calling numeric_pipeline function\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, list(num_attrs)),\n",
    "        (\"cat\", OneHotEncoder(), cat_attrs),\n",
    "        ])\n",
    "    prepared_data = full_pipeline.fit_transform(data)\n",
    "    return prepared_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Raw Data to process data in 2 steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.85657842, -1.07804475, -1.15192977, -1.17220298,  1.21586943,\n",
       "       -0.54436373,  1.70952741,  1.29565517,  1.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_df=preprocess_origin_col(data)\n",
    "prepared_data=data_pipeline(preprocess_df)\n",
    "prepared_data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning Models:\n",
    "    1.Linear Regression\n",
    "    2.Decision Tree\n",
    "    3.Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()              #Calling Linear Regression\n",
    "lin_reg.fit(prepared_data, data_label)    #Fitting our data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of samples:  [29.08069379 27.78336755 26.08031176 12.70419279 22.23454159]\n",
      "Actual Labels of samples:  [32.0, 31.0, 26.0, 18.0, 26.0]\n"
     ]
    }
   ],
   "source": [
    "# Testing the predictions with sample\n",
    "sample_data = data.iloc[:5]\n",
    "sample_labels = data_label.iloc[:5]\n",
    "\n",
    "sample_data_prepared = data_pipeline(sample_data)\n",
    "\n",
    "print(\"Prediction of samples: \", lin_reg.predict(sample_data_prepared))\n",
    "\n",
    "print(\"Actual Labels of samples: \", list(sample_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9590402225760872"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lg_prediction=lin_reg.predict(prepared_data)\n",
    "lin_mse= mean_squared_error(data_label,lg_prediction)\n",
    "lin_rmse= np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through linear regression we get mean squared error of 2.95 which is good but still we make decision after comparing it with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991628933369083"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "tree_reg= RandomForestRegressor()\n",
    "tree_reg.fit(prepared_data,data_label)\n",
    "tree_prediction = tree_reg.predict(prepared_data)\n",
    "tree_mse=mean_squared_error(data_label,tree_prediction)\n",
    "tree_rmse=np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the error has reduced but still we will go with one more model and compare the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dec_tree= DecisionTreeRegressor()\n",
    "dec_tree.fit(prepared_data,data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_prediction = dec_tree.predict(prepared_data)\n",
    "dec_mse=mean_squared_error(data_label,dec_prediction)\n",
    "dec_rmse=np.sqrt(dec_mse)\n",
    "dec_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here error which we received is 0 but no model can be perfect. This means overfitting has occured.\n",
    "Because of similar scenario, we don't touch our test data until we are sure of the efficiency of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation using  Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-cross valiation technique divides the training data into K distinct subsets called folds, then it trains on individual fold and evaluate the model K times, picking a different fold for evaluation every time and training on other K-1 folds.\n",
    "\n",
    "Result is an array containing the K evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Function for cross_validation\n",
    "def cross_validation(estimator,independent,dependent,cv=None):\n",
    "    scores=cross_val_score(estimator,independent,dependent,scoring=\"neg_mean_squared_error\",cv=cv)\n",
    "    return scores\n",
    "\n",
    "# Function to calculate Root mean square error\n",
    "def root_mean_square(scores):\n",
    "    rmse_array=np.sqrt(-scores)\n",
    "    rmse=np.mean(rmse_array)\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating both Decission Tree and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Root mean Square of DecisionTreeRegressor: 3.2157097076785552\n",
      "----------------------------------------------------------------------\n",
      "Mean Root mean Square of LinearRegression: 3.0757081793709324\n",
      "----------------------------------------------------------------------\n",
      "Mean Root mean Square of LinearRegression: 2.5651381120764616\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeRegressor\n",
    "dec_tree_scores=cross_val_score(dec_tree,prepared_data,data_label,scoring=\"neg_mean_squared_error\",cv=10) \n",
    "dec_cross_rmse=root_mean_square(dec_tree_scores)\n",
    "print(\"Mean Root mean Square of DecisionTreeRegressor:\",dec_cross_rmse)\n",
    "\n",
    "# LinearRegression\n",
    "linear_reg_scores=cross_val_score(lin_reg,prepared_data,data_label,scoring=\"neg_mean_squared_error\",cv=10) \n",
    "linear_reg_rmse=root_mean_square(linear_reg_scores)\n",
    "print(\"-\"*70)\n",
    "print(\"Mean Root mean Square of LinearRegression:\",linear_reg_rmse)\n",
    "\n",
    "#RandomForestRegressor\n",
    "tree_cv=cross_validation(tree_reg,prepared_data,data_label,cv=10)\n",
    "tree_rmse=root_mean_square(tree_cv)\n",
    "print(\"-\"*70)\n",
    "print(\"Mean Root mean Square of LinearRegression:\",tree_rmse)\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of all three model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>LinearRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.565138</td>\n",
       "      <td>3.21571</td>\n",
       "      <td>3.075708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForestRegressor  DecisionTreeRegressor  LinearRegression\n",
       "0               2.565138                3.21571          3.075708"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_values=np.array([tree_rmse,dec_cross_rmse,linear_reg_rmse])\n",
    "root_mean_data=pd.DataFrame([root_mean_values],columns=[\"RandomForestRegressor\",\"DecisionTreeRegressor\",\"LinearRegression\"])\n",
    "root_mean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that RandomForestRegressor provides us with the minimum error so we will continue with the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters are parameters that are not directly learnt with the model. It is possible and recommended to search the \n",
    "hyper-parameter space or best cross validation score.\n",
    "The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter. For instance, the following param_grid\n",
    "\n",
    "To find the names and current values for all parameters for a given estimator use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg.get_params() # Output every parameter for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We create 2 grids to be explored\n",
    "param_grid=[\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg=RandomForestRegressor()\n",
    "grid_search= GridSearchCV(forest_reg,\n",
    "                          param_grid,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          return_train_score=True,\n",
    "                          cv=10)\n",
    "grid_search.fit(prepared_data,data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the results\n",
    "cv_scores=grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing all the parameters along with their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6199329776316036 {'max_features': 2, 'n_estimators': 3}\n",
      "3.0725535032350426 {'max_features': 2, 'n_estimators': 10}\n",
      "2.874682901468295 {'max_features': 2, 'n_estimators': 30}\n",
      "3.5210187486967226 {'max_features': 4, 'n_estimators': 3}\n",
      "2.8531561824780822 {'max_features': 4, 'n_estimators': 10}\n",
      "2.7717499718744514 {'max_features': 4, 'n_estimators': 30}\n",
      "3.4351578857194887 {'max_features': 6, 'n_estimators': 3}\n",
      "2.786296858098866 {'max_features': 6, 'n_estimators': 10}\n",
      "2.7219653153725885 {'max_features': 6, 'n_estimators': 30}\n",
      "3.141053942559995 {'max_features': 8, 'n_estimators': 3}\n",
      "2.8086219625697284 {'max_features': 8, 'n_estimators': 10}\n",
      "2.64981148375079 {'max_features': 8, 'n_estimators': 30}\n",
      "3.307987238471828 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "2.949595813617465 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "3.2220672218157773 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "2.9353679685666494 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "3.3946177816526775 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "2.9721363894918977 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n",
      "------------------------------------------------------------\n",
      "RandomForestRegressor(max_features=8, n_estimators=30)\n"
     ]
    }
   ],
   "source": [
    "for mean_square,param in zip(cv_scores['mean_test_score'],cv_scores['params']):\n",
    "    print(np.sqrt(-mean_square),param)\n",
    "\n",
    "print(\"-\"*60)\n",
    "# TO check for the parameters selected by our estimator.\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13837777, 0.25679354, 0.14163484, 0.27639793, 0.01487727,\n",
       "       0.12368389, 0.02538391, 0.01753645, 0.00228627, 0.00128474,\n",
       "       0.0017434 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance=grid_search.best_estimator_.feature_importances_\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acc_power', 0.025383910347666735),\n",
       " ('acc_cyl', 0.017536448121938126),\n",
       " ('Weight', 0.27639793248834454),\n",
       " ('Model Year', 0.1236838860172806),\n",
       " ('Horsepower', 0.14163484117213804),\n",
       " ('Displacement', 0.2567935376155446),\n",
       " ('Cylinders', 0.1383777712327786),\n",
       " ('Acceleration', 0.01487726597165504)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra=[\"acc_power\",\"acc_cyl\"]\n",
    "num=[\"float64\",\"int64\"]\n",
    "\n",
    "num_aatr= list(data.select_dtypes(include=num))\n",
    "\n",
    "attr=num_aatr+extra\n",
    "\n",
    "sorted(zip(attr,feature_importance),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that features [Weight, Model Year, Horsepower, Displacement, Cylinders] have got the larger number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model on the entire Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.981193995514028"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=grid_search.best_estimator_\n",
    "\n",
    "auto_test_data=strat_test_set.drop(\"MPG\",axis=1)\n",
    "auto_test_label=strat_test_set[\"MPG\"].copy()\n",
    "\n",
    "auto_test_process=preprocess_origin_col(auto_test_data)\n",
    "auto_test_prepared=data_pipeline(auto_test_process)\n",
    "\n",
    "final_predict=final.predict(auto_test_prepared)\n",
    "final_mse=mean_squared_error(final_predict,auto_test_label)\n",
    "final_rmse=np.sqrt(final_mse)\n",
    "final_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to cover entire workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(config,model):\n",
    "    if type(config)==dict:                # Checking whether incoming data is a DataFrame or not, if not convert it into one\n",
    "        df=pd.DataFrame(config)\n",
    "    else:\n",
    "        df=config\n",
    "    preproc_df=preprocess_origin_col(df)  # Encoding\n",
    "    prep_data=data_pipeline(preproc_df)   # Data and Numeric Pipeline\n",
    "    pred=model.predict(prep_data)         # Prdiction\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "------------------------------------------------------------\n",
      "0 -> 33.84666666666666\n",
      "1 -> 17.65333333333333\n",
      "2 -> 19.25\n"
     ]
    }
   ],
   "source": [
    "#Creating our own example\n",
    "vehicle_config = {\n",
    "    'Cylinders': [4, 6, 8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin': [3, 2, 1]\n",
    "}\n",
    "\n",
    "values=predict_func(vehicle_config, final)\n",
    "print(\"Predictions:\")\n",
    "print(\"-\"*60)\n",
    "for i in range(len(values)):\n",
    "    print(i,\"->\" ,values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"model.bin\",\"wb\") as f_out:\n",
    "    pickle.dump(final,f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.84666667, 17.65333333, 19.25      ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"model.bin\",\"rb\") as f_in:\n",
    "    model=pickle.load(f_in)\n",
    "\n",
    "predict_func(vehicle_config,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
